![GitHub Logo](https://s3.ap-south-1.amazonaws.com/greyatom-social/logo.png)

## Pre-Read
1. [XGBoost Documentation](http://xgboost.readthedocs.io/en/latest/python/python_intro.html)
2. [Complete Guide to Parameter Tuning in XGBoost](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)

## Learning Objectives
1. Learn what Boosting is and how use it in ML
2. Learn what Gradient Boosting Machines are and how to use them to build ML models
3. Learn to configure GBM using early-stopping and hyperparameter tuning to achieve superior performance
4. Learn how to interpret XGBoost models

## Hands-on Skills
1. Implementation of GBM using sklearn library
2. Building, Saving and Reloading models using XGBoost library
3. Implementing Early-stopping and Hyperparameter tuning
3. Interpreting and visualizing XGBoost models

## Slides
@[gslides](1kHHvx3lCibtD9tU0twxMpkU0D3k2PHrTFZwInMbxrPs)

## Notebooks
To be updated

## Assignments
To be updated

## Post Reads
1. [XGBoost: A Scalable Tree Boosting System](http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf)
2. [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)
